import requests
from io import BytesIO
from PIL import Image
import uvicorn
import numpy as np
import os
import faiss
import google.generativeai as genai
from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from linebot import LineBotApi, WebhookHandler
from linebot.models import (
    MessageEvent, TextMessage, ImageMessage, FlexSendMessage,
    BubbleContainer, CarouselContainer, BoxComponent,
    TextComponent, ButtonComponent, URIAction
)
from linebot.exceptions import InvalidSignatureError
from sentence_transformers import SentenceTransformer
from typing import Dict
from contextlib import asynccontextmanager

ACCESS_TOKEN = os.getenv("LINE_ACCESS_TOKEN", "RMuXBCLD7tGSbkGgdELH7Vz9+Qz0YhqCIeKBhpMdKvOVii7W2L9rNpAHjYGigFN4ORLknMxhuWJYKIX3uLrY1BUg7E3Bk0v3Fmc5ZIC53d8fOdvIMyZQ6EdaOS0a6kejeqcX/dRFI/JfiFJr5mdwZgdB04t89/1O/w1cDnyilFU=")
CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "175149695b4d312eabb9df4b7e3e7a95")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyBfkFZ8DCBb57CwW8WIwqSbUTB3fyIfw6g")

# Setup LINE API
line_bot_api = LineBotApi(ACCESS_TOKEN)
handler = WebhookHandler(CHANNEL_SECRET)

# Setup Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

class RAGSystem:
    def __init__(self, embedding_model: str = 'all-MiniLM-L6-v2'):
        self.embedding_model = SentenceTransformer(embedding_model)
        self.database = {
            'documents': [],
            'embeddings': [],
            'metadata': []
        }
        self.create_faiss_index()

    def add_document(self, text: str, metadata: dict = None):
        embedding = self.embedding_model.encode([text])[0]
        self.database['documents'].append(text)
        self.database['embeddings'].append(embedding.tolist())
        self.database['metadata'].append(metadata or {})
        self.create_faiss_index()

    def create_faiss_index(self):
        if not self.database['embeddings']:
            self.index = None
            return
        embeddings = np.array(self.database['embeddings'], dtype='float32')
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings)

    def retrieve_documents(self, query: str, top_k: int = 3):
        if not self.database['embeddings'] or self.index is None:
            return []
        query_embedding = self.embedding_model.encode([query]).astype('float32')
        D, I = self.index.search(query_embedding, top_k)
        return [self.database['documents'][i] for i in I[0] if i < len(self.database['documents'])]

    def clear_database(self):
        self.database = {
            'documents': [],
            'embeddings': [],
            'metadata': []
        }
        self.index = None

rag = RAGSystem()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Add your sample documents here
    sample_documents = [EMERGENCY_MANUAL, FIRST_AID_MANUAL, HEALTH_CHECK_MANUAL, MEDICAL_CONTACTS]
    for doc in sample_documents:
        rag.add_document(doc)
    yield
    rag.clear_database()

app = FastAPI(lifespan=lifespan)

EMERGENCY_MANUAL = """‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô" üè•
‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å:
‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô: ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "Emergency" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û
‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ö‡∏≠‡∏ó: ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏ê‡∏°‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô "‡∏°‡∏µ‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
"""

FIRST_AID_MANUAL = """‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô ‡πÉ‡∏´‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
1.‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
2.‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á
3.‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏¢‡πÉ‡∏à: ‡∏î‡∏π‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏ß‡∏á‡∏≠‡∏Å ‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏≤‡∏¢‡πÉ‡∏à
4.‡πÇ‡∏ó‡∏£‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠: ‡πÅ‡∏à‡πâ‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏π‡πâ‡∏ä‡∏µ‡∏û‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô 1669 ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
5.‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏ê‡∏°‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•: ‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô CPR ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
"""

HEALTH_CHECK_MANUAL = """üè• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
- ‡∏ß‡∏±‡∏î‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢
- ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï
- ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏±‡∏î‡∏≠‡∏≠‡∏Å‡∏ã‡∏¥‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
üëâ ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
"""

MEDICAL_CONTACTS = """üìû ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå
‡πÄ‡∏´‡∏ï‡∏∏‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå: ‡πÇ‡∏ó‡∏£ 1669 (‡∏ï‡∏•‡∏≠‡∏î 24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
‡∏™‡∏≤‡∏¢‡∏î‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï: ‡πÇ‡∏ó‡∏£ 1323
‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏û‡∏¥‡∏©‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤: ‡πÇ‡∏ó‡∏£ 1367
‡∏™‡∏≤‡∏¢‡∏î‡πà‡∏ß‡∏ô‡∏Å‡∏£‡∏°‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÇ‡∏£‡∏Ñ: ‡πÇ‡∏ó‡∏£ 1422
"""

def get_manual_response(user_message: str) -> str:
    user_message = user_message.strip().lower()
    manuals = {
        "emergency": EMERGENCY_MANUAL,
        "‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô": EMERGENCY_MANUAL,
        "‡∏Å‡∏≤‡∏£‡∏õ‡∏ê‡∏°‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô": FIRST_AID_MANUAL,
        "‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô": FIRST_AID_MANUAL,
        "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û": HEALTH_CHECK_MANUAL,
        "‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÅ‡∏û‡∏ó‡∏¢‡πå": MEDICAL_CONTACTS,
        "contact medical": MEDICAL_CONTACTS
    }
    return manuals.get(user_message)

def create_bubble_container(text: str) -> BubbleContainer:
    return BubbleContainer(
        header=BoxComponent(
            layout='vertical',
            contents=[
                TextComponent(
                    text="WildSafe",
                    weight='bold',
                    align='center',
                    color='#FFFFFF',
                    size='xl'
                )
            ],
            background_color='#27AE60'
        ),
        body=BoxComponent(
            layout='vertical',
            contents=[
                TextComponent(
                    text=text,
                    wrap=True,
                    size='sm'
                )
            ]
        )
    )

def create_flex_message(text: str) -> FlexSendMessage:
    bubble = create_bubble_container(text)
    return FlexSendMessage(alt_text="WildSafe Message", contents=bubble)

def create_carousel_message(texts: list) -> FlexSendMessage:
    bubbles = [create_bubble_container(text) for text in texts]
    carousel = CarouselContainer(contents=bubbles)
    return FlexSendMessage(alt_text="WildSafe Carousel", contents=carousel)

@app.post('/message')
async def message(request: Request):
    signature = request.headers.get('X-Line-Signature')
    if not signature:
        raise HTTPException(status_code=400, detail="X-Line-Signature header is missing")
    
    body = await request.body()
    try:
        handler.handle(body.decode("UTF-8"), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")
    return {"status": "ok"}

@handler.add(MessageEvent, message=(TextMessage, ImageMessage))
def handle_message(event: MessageEvent):
    if isinstance(event.message, TextMessage):
        user_message = event.message.text
        manual_response = get_manual_response(user_message)
        
        if manual_response:
            reply = create_flex_message(manual_response)
        else:
            # Check if the message matches predefined keywords exactly
            relevant_to_rag = any(user_message.strip().lower() == phrase for phrase in ['‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô', '‡∏ä‡πâ‡∏≤‡∏á', '‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà'])
            
            if relevant_to_rag:
                retrieved_docs = rag.retrieve_documents(user_message, top_k=3)
                if retrieved_docs:
                    texts = ["‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà" if "http" in doc else doc for doc in retrieved_docs]
                    reply = create_carousel_message(texts)
                else:
                    # Use Gemini if RAG has no results
                    gemini_response = model.generate_content(user_message + " ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ‡πÉ‡∏ô 2-3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
                    reply = create_flex_message(gemini_response.text.strip().split("\n")[:3])
            else:
                # Use Gemini for non-matching queries
                gemini_response = model.generate_content(user_message + " ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ‡πÉ‡∏ô 2-3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
                reply = create_flex_message("\n".join(gemini_response.text.strip().split("\n")[:3]))

        line_bot_api.reply_message(
            event.reply_token,
            [reply]
        )

    elif isinstance(event.message, ImageMessage):
        try:
            headers = {"Authorization": f"Bearer {ACCESS_TOKEN}"}
            url = f"https://api-data.line.me/v2/bot/message/{event.message.id}/content"
            response = requests.get(url, headers=headers, stream=True)
            response.raise_for_status()
            image_data = BytesIO(response.content)
            image = Image.open(image_data)
            
            if image.size[0] * image.size[1] > 1024 * 1024:
                message = "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
            else:
                try:
                    gemini_response = model.generate_content("‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ‡πÉ‡∏ô 2-3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
                    message = "\n".join(gemini_response.text.strip().split("\n")[:3])
                except Exception:
                    message = "‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏∞ üôèüèª"
                
        except Exception:
            message = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î, ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏áüôèüèª"
            
        reply = create_flex_message(message)
        line_bot_api.reply_message(event.reply_token, [reply])



if __name__ == "__main__":
    uvicorn.run("main:app", port=8000, host="0.0.0.0")
